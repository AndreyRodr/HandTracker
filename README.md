# HandTracker - Tradutor de LIBRAS com Intelig√™ncia Artificial

Este reposit√≥rio cont√©m um sistema h√≠brido de reconhecimento de **L√≠ngua Brasileira de Sinais (LIBRAS)**, dividido em duas abordagens distintas de Intelig√™ncia Artificial:

1.  **Modelo Din√¢mico (Gestos em V√≠deo):** Capaz de entender movimentos e frases (ex: gestos que dependem de movimento corporal) utilizando **MediaPipe Holistic** e redes **LSTM**.
2.  **Modelo Est√°tico (Alfabeto em Imagem):** Capaz de reconhecer letras do alfabeto (A-Y) utilizando **MobileNetV2** e Transfer Learning.

---

## üìã Pr√©-requisitos

* Python 3.8 ou superior
* Webcam funcional
* Conta no Kaggle (para baixar o dataset do modelo est√°tico)

---

## üõ†Ô∏è Instala√ß√£o Geral

Recomenda-se criar um ambiente virtual para evitar conflitos de vers√µes.

```bash
# Clone o reposit√≥rio
git clone [https://github.com/seu-usuario/HandTracker.git](https://github.com/seu-usuario/HandTracker.git)
cd HandTracker

# Crie um ambiente virtual (Opcional, mas recomendado)
python -m venv venv

# Ative o ambiente
# No Windows:
venv\Scripts\activate
# No Linux/Mac:
source venv/bin/activate
````

## üöÄ 1. Modelo Din√¢mico (Reconhecimento de Gestos)

Este m√≥dulo foca no reconhecimento de sinais que envolvem movimento (v√≠deo). Ele extrai pontos-chave do corpo (pose) e das m√£os e analisa a sequ√™ncia temporal.

### üìÇ Estrutura da Pasta `Din√¢mico/`

  * `keypointsExtraction.py`: Processa v√≠deos brutos e extrai coordenadas (features).
  * `aumentar_dados.py`: Cria varia√ß√µes dos dados (zoom, ru√≠do) para melhorar o treino.
  * `treinar_final.py`: Treina a rede neural (LSTM).
  * `testar_libras.py`: Tradutor em tempo real via webcam.
  * `avaliar_modelo.py`: Gera m√©tricas e matriz de confus√£o.

### üë£ Passo a Passo para Uso

1.  **Instale as depend√™ncias:**

    ```bash
    pip install -r Din√¢mico/requirements.txt
    ```

2.  **Prepare os Dados (Se tiver v√≠deos novos):**
    Coloque seus v√≠deos organizados em pastas (ex: `separados/Ola`, `separados/Obrigado`) e execute:

    ```bash
    cd Din√¢mico
    python keypointsExtraction.py
    ```

    *Isso criar√° arquivos `.npy` na pasta `dataset_features`.*

3.  **Aumente o Dataset (Data Augmentation):**
    Para tornar o modelo mais robusto:

    ```bash
    python aumentar_dados.py
    ```

4.  **Treine o Modelo:**

    ```bash
    python treinar_final.py
    ```

    *Isso gerar√° o arquivo `libras_model.keras` e `actions.npy`.*

5.  **Teste em Tempo Real:**
    Para ver a tradu√ß√£o a acontecer na sua webcam:

    ```bash
    python testar_libras.py
    ```

    *Pressione 'q' para sair.*

6.  **Avalie a Performance:**
    Para ver a acur√°cia e a Matriz de Confus√£o:

    ```bash
    python avaliar_modelo.py
    ```

-----

## üì∑ 2. Modelo Est√°tico (Alfabeto Manual)

Este m√≥dulo foca na classifica√ß√£o de imagens est√°ticas (frames individuais) para reconhecer as letras do alfabeto de LIBRAS.

### üìÇ Estrutura da Pasta `Est√°tico/`

  * `app.py`: Aplica√ß√£o principal com Menu (Webcam ou Upload de Imagem).
  * `download_data.py`: Baixa o dataset do Kaggle automaticamente.
  * `config.py`: Configura√ß√µes globais (caminhos, par√¢metros).

### üë£ Passo a Passo para Uso

1.  **Instale as depend√™ncias:**

    ```bash
    pip install -r Est√°tico/requirements.txt
    ```

2.  **Configura√ß√£o do Dataset:**
    Este projeto usa o dataset `williansoliveira/libras` do Kaggle.

      * Crie uma chave de API no Kaggle e coloque o arquivo `kaggle.json` na pasta do seu utilizador (`~/.kaggle/` ou `%USERPROFILE%/.kaggle/`).
      * Execute o script de download:

    <!-- end list -->

    ```bash
    cd Est√°tico
    python download_data.py
    ```

3.  **Execute o Aplicativo:**
    O app abrir√° um menu interativo no terminal.

    ```bash
    python app.py
    ```

    **Op√ß√µes do Menu:**

      * **1. Tradu√ß√£o em Tempo Real:** Abre a webcam e desenha um box verde. Coloque a m√£o dentro do box para traduzir a letra.
      * **2. Traduzir uma Imagem:** Abre uma janela para selecionar um arquivo de imagem (`.jpg`, `.png`) do computador e exibe a predi√ß√£o.

-----

## üß† Tecnologias Utilizadas

  * **Linguagem:** Python
  * **Vis√£o Computacional:** OpenCV, MediaPipe
  * **Deep Learning:** TensorFlow, Keras
  * **Arquiteturas:**
      * *Din√¢mico:* LSTM Bidirecional (Long Short-Term Memory)
      * *Est√°tico:* MobileNetV2 (Transfer Learning)
  * **Manipula√ß√£o de Dados:** NumPy, Pandas, Scikit-Learn

-----

## ü§ù Desenvolvedores

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/AndreyRodr">
        <img src="https://avatars.githubusercontent.com/u/134998417?v=4" width="100px;" alt="Foto do Andrey"/><br>
        <sub>
          <b>Andrey Rodrigues</b>
        </sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/LucassTeixeiraN">
        <img src="https://avatars.githubusercontent.com/u/82536301?v=4" width="100px;" alt="Foto do Lucas"/><br>
        <sub>
          <b>Lucas Teixeira</b>
        </sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/jptrava">
        <img src="https://avatars.githubusercontent.com/u/164881489?v=4" width="100px;" alt="Foto do Jo√£o"/><br>
        <sub>
          <b>Jo√£o Pedro Andrade</b>
        </sub>
      </a>
    </td>
  </tr>
</table>
